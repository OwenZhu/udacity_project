{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAHF9JREFUeJzt3UmPZOl1HuAvxsyMrKzKqsqau6rYA5vNbropkjJJmYIs\nUIBXWtn+BV7YO/8Yr73wymtDNAwIggwSMEmBNMeW2Wz2VOzumquyco6M2QttzI2Bc5gChYPn2Z88\nEd+9cd+8q7ezWq0aAFBT9w/9AQCAfzyCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/T/0B/jH8l/+w79fZebGx9PwTK+f\n+3+pc/tGeGZvtJHa9faFYWruk1/+LDzznR/+PLVrbzILz/R6ybPvdFJzg7X18MylKzupXec34t/t\n83eupHb9+be+Hp6Zz+LXq7XWnu0fpeYGWxfDM+9+8NvUrr/97g/jQ8nnwNogN3dhMAjPDPuL1K5p\n4lrPZ7nfWFstU2NrvbXwzMkq/rxvrbUXp/F46eZ+Lu073/+75EH+P7t/3z8AAPzTJegBoDBBDwCF\nCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+te3P84NddfxJuT\nBv1UUV67v5qEZ94f5yqQ3v7iK6m55TT+Ga/t5NraNlLfLXf22fa6k0n8PPZ3X6R2HXXiTWOT03Fq\n15e/+o3wzOzkNLXr2fPceVxbjzc3LqcHqV0ba/H7atlyrWtXt86l5r70ymvhmadP7qd2jceH4Zmj\no1xLYevGW/laa22tPw/P3Lx+IbVrNrwanvngV/dSu86CN3oAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZUpuPT9dScyfj/fDMsJMr92iLeKFCtzNMrXr2\n28epuZ88+Cw88+snudKS1SReSpEtp1lfX0/NzebxopnWzf0/vb4Rv4f3xrlilR+983545sblXCHI\nZJ67ZpkCo7XkE24wSHzG3NG3L7z6amruc3fuhme2t0apXY8e3gvPLGe55+K5izdSc4tBvPRotJYr\n3rm5Ey8i+rSXO/uz4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLLtdeNeriFrtxtvJ+ssJqldl/vx4z93/mJq1+lxvJWvtdb2DuPf7eB0ltq1\nSpz9YpFok2ut9ZKfsZ/533gWb11rrbXjafzsz61yu370i1+GZ15/7bXUrjdevZOa6w/j7V+f+1yu\nGe54OQjPPH74NLXr4HCcmmvrm+GRP/6zt1Orfv7j74VnxvN4G2VrrR3Oci1vz4/jz8ZL41zD3q3e\nYXjm9Cjb2vj780YPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANA\nYYIeAAorW2qz1tlNzd0YxYsYtlu8AKO11i5d3AjPfLyKlym01trmxjI1t9aJl6SMOrnbara5Fp+Z\n58ppTie5IqJF4n/jjVGupGO4Fr+vrt++kdp186Xb4ZlnR7lCkEcHuRKXb3zj6+GZ3cePUrv+9b/5\nVnjmf/z3v07t+uEP/i41d+dLXw3PfPvtr6V2fXj/o/DMx9//cWrX/nQrNXc0jz/jvvjP42fYWmvj\n2YvwzM7OemrXWfBGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNAD\nQGGCHgAKE/QAUFjZ9rrhZu6rvbJ1NTzz8iq368Iw0Wa0/1lq12g73gzXWmvHw5PwzHKwSO364z+K\nN0lduxq/Xq219tEHH6TmPv3kfnim28u1G67m8Xa49W7u7P/kG/Gzfxq/NVprrf3oe99Nzb333p3w\nzGKc/JCbF8Mje8e5RsSjWe5964OHz8Mzx8teatfxPP4Zn+zlzmOyfi419/m7r4Rntq/dTO16+jx+\n9t/+9lupXWfBGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCF\nCXoAKEzQA0BhZdvrjqa5xrALvc3wzOzZi9SuT/fiTWh/+uU3UrvG0+PU3K1lfGZ9tErt+uZ2/Ozf\nvLKT2nWyzH3GZ2vxFsCT/dz9sZjGZ/rTw9Suu598HJ7Z2Jundl26sp2am/39z8Iz2ebAH/7q3fDM\new8epHadznMtb/c/iTdZPnn+NLXr61/5Znjm7vbt1K7/9F//W2puOn4UnvnJj5+ldj1+/GF45qt/\nkXt2nwVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nsLKlNld666m5W60Xnjl/fiu16+cv4qUULyb7qV13r99Izf3bJy+HZwYHuQKdy+/Hz2Ptw4epXYvl\nLDX3uU58ZrBIDLXWuv34Pbzo5EpcJj/6aXjmQrKMZbkTLy9qrbXFPNGwdLBI7TrfOxeemRzn7vtL\n8UdOa6210Wocnjl49NvUrltffD08s7WZewZ//dVbqbkn+/EWqEdHJ6ldJye74ZmP3n8/tesseKMH\ngMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx7\n3Rtbo9Tc5vNn4ZleN9Gq1Vp7/aWXwjOHj5+mdrVVrkHtVmcVnhkNc7t6iUaozjL++VprLd5z9Q8m\n3cT/xsO11K7BKv7d+pmGt9baoBtv85tt5WrXVie51rv5JH4ei5a7F69143fItzdyrXzTzjA1t7h5\nLTyzfu9eatdJ5iMmWz3feuO11NyNk/g1uzGbp3a9/urN8MxrO/FGxLPijR4AChP0AFCYoAeAwgQ9\nABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21Gb3wUepuck8XoIx7uWKRE4u\nxEsONk7i5SOttXb67oepuUVvEZ6Zb+Zuq24vXkqxlixx6bT11Nw8UQ60WOY+42owiM+kNuXm+ldf\nSe3a2su9X5wmLtn07sXUrovzo/DM5mmuKmm+lytWOXqyH545efD91K6H//sX4Znzb72e2vX8Ua64\nazq6FJ6Zj1Or2snzF+GZg0G2Suv3540eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdc+P9lJznx6fhmfmy1z71LBzPTwzuriT2vV8fJiau95b\nC89snOb+f1wcxJv5JtNcm1/byZ3j5uuvhWdOE01orbV29OwgPLO2jLfrtdZabzIJz0ye5u6ptpZr\nlOtsx9se+51cn9/yIP4c2Hgr1+bXhvHv1Vproyfx6rXj+/dTu/Z+/UF4ZvnJ49SurUtbqbnd7XhL\n5PNHud/mwyefhWdeHt5I7ToL3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAoTNADQGGCHgAKK9te9+I03j7VWmuPTuJtRrOD49SunWtXwjOr21dTu9Yu5hqh1g7i\nzXz9B09Tu6ZHJ+GZoxZvrGqttcW5jdTc4O6d8Ey/s0jt2tyOn8fsN5+kds0SLYCn3Vxz4NafvZma\nO9l7Fh9679epXW2eeAd6mPh8rbXJMte0Obh+Mzxz/V9+M7VrbaMXntn9zYepXdsn8V2ttXbhbrxp\n85NHuYa9jV68FXEwGKZ2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLKlNrdvv5Sa6358PzyzMU6taotpvBhhrTNI7XpxfJCa+8Gnn4Vnbp4epna9\n0eIHOUmUsbTW2vh+/Dq31tr0p7+K72rx69xaa51bt8Izp69fT+06mY/CM2+/miunOe6eS82NH9wL\nzwz3c+VW8/PxApLpJ8lCoce5UqzB1SfhmZNruVKswaUL4ZmLf/HV1K69Tx+m5rZ34mU4Xz13N7Xr\nb/7Xi/DM2na8xOyseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAorGx73fWb11Jzh/efhWdGFzupXa2zFh4ZdHO7Hj57npr7z7/4P+GZL1zOtZP9\nx/XN8Mwo+a/q6vgoNbf7Try9bvdKvPmrtdY+msRbzabJprybr98Mz9y5mPte04ePU3PnEq1mneU0\ntasdxn9na92N1KqD8UlqbvHRR+GZ1YNHqV0vtuLPqs0v5BpEb778amru9FH8vroyij9zWmvtK196\nLTxz++XceZwFb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAU\nJugBoLCypTb7ixepuf5qPzwz6OeOcdqLF5DszcepXbvjXNnJfBX/bgeDXLnH/cEoPLO9mqd2Tbu5\nudVqEp7ZX+ZKSz57Ei+1Od9dT+16kbhkf3X/r1K7vnDrVmru1Uvx73Z57Xpq1/G9++GZxTh+vVpr\nbbXI3YsvXjxN7Mo9B6br8VKb2X68IKy11qa/fD81N0oUOk3WB6ldd998Kzwze/Db1K6z4I0eAAoT\n9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdcPV\nMjXXX87CMzvdXAPStBdvrerPpqldJ6e587h15Up45qWXb6d23T9KNPOtcm1cw2RrVWce/8lMl/HG\nu9Zau3F5JzzTzxWhtYOnj8Izq91cK9+D57mWt/3RMDxzZxL/PbfWWvdZvL2ujXOH353n3rfG8/g5\nnixyz49VohVxNO6kdj28/1lqbtSJ7zue567Z9iQ+t/P266ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypzcZ4lJp7ML8QnrnaPU3tujjeC8/0\nnzxM7ZofvkjNffHNl8Mzd77w+dSu3V+8F5650emldrVBrgxnsIr/b7xxlCtx6bf4ZxyNNlK7fvPh\nvfDMznHuPeGVz11KzX02jBfUPP4g93vZONwNz3TmuXuqs8jdw6eJUqxpN3fNpsfxXbuLw9Su0eh8\nau5wGi+POp7krtnu/cfhmf6d66ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeA\nwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+v2j+NNV6219t39eEvT/HJqVfvWchqe2XjyKLVrfXaS\nmvvK174dnrl5+7XUru/86J3wzP4k1xy46Ofuj1miLW9j1UntOv0sfq17l3LNcK9c3AnPnC72U7v6\nm8PU3Nt/+vXwzG680Owf5n7yJDwzWeaa0Jb9tdTcOHFfbW4mH1Ybm+GR8TDXyre8fDE1d9ri+x49\njbcUttba/t6z8MyLX7+f2vWXqanf5Y0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtddODB6m5D54/Ds+MZ7k2ru2X4o1hXx7kWte2+vFWvtZa\ne/n27fDM+XO5BrXJIt7mNzmJz7TW2nCwSM2druL7ht3c/TGcxq/ZeDfXxtXtxx8Fy16ure3x81wD\n44t3fxWeGa3nGtQO18/FZzZGqV2Tc1upuePj4/DMaCf329ydxlsiD+e531h3Nk7NPXx0FN+1Hm/l\na621g1n8ObB5kGt7PAve6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhQl6AChM0ANAYWVLbf7V3VxZwdPdeJnFjz8+Se36m3vxkoONV3Lfa3RuLTW31YsXdcwO4wUYrbW2\n6MRLMI4nuV3rvdytv+gl/jfu5P6fXnbjc7vH8WKP1lpbncYLdIbHubOf7eWKiFYffhKeGSXfZaaj\n8+GZd+aT1K57z56k5taX8ZnhMlcYM1iP/146s05q1+lerpjpeBUvB+qfG6R2LQbx73b34nZq11nw\nRg8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFBY\n2fa612/mvtq/G90Jz9xeu5/a9T/fizeN/e29WWrXH929mZo7+vDj8Mxe8v/H3jJex7U3zTUHXhnF\nm65aa22x6oVnZsvcNXu6ip/Hs1G8fbG11k778fa6rU7uN7Z5IXf2y2n8M7bnB6lda2vxlsjPTnPN\ncM8Xq9Tc9UG8eW20mbs/tjbj57Ea59oNn01z59jvxZ8Fvd3c8+NLq2F45txh7jlwFrzRA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCypbaTJJlJ5fWO+GZ\nP3l9J7Xr2XG8tOQn9/dTu959/CI19/lEUcd0mLutVsv4/52Hp5Pcrkm8lKK11gbr8e+2WuZKS1pi\nbmNtPbXqcBUvIDm4cy216/Jbb6TmevGfS3vnr7+X2nU7cV+9dPFKalebTFNj6/34gezPcoUxx8/j\nz9PryYKlmzuXU3PDbvy3OdjNPU/vHsYLyW5vb6d2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoA\nKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIWVba/r9HJfrTOPt1bd2M41hv2Lly+EZw6m\n8Zax1lq7t5dr8zvpxdv8rt6+ndrVG47CM6fzXDPc6eFhaq4/W4RnhoON1K743dHa/PHT1K7zi3l4\nZnKQu6d2Z4kautba9sWL8ZlO7l1mcBr/brc2N1O7hsn3rc7mWnxmkPuM3aN4w961fvz33FpriQLR\n1lpr3Un8t3mSfA5c6MXvj1fv5HLiLHijB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQ\nmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91qlatAWi0T7WTLeONda629eSl+/E9vnEvtOp7kPuN8\nHG/L27l8JbVr/Vy8r21vmWuvm01nqbl5Ym7SyzUOdju98Mz55L/umV6t6cF+btlp7jxWj56EZ15q\nuefAoBdv89sa587jai/Xbvgi0Ui5thVvAGytteUsfmPNT/ZSuw4muVbERHldW06OU7tuvHk1PPPy\nndxz8Sx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8A\nhZUttVl2cv/DLFq8SKTNcwUpF/rxwo2v3N5J7Xp+uJuamz5+GJ6ZHeeKIoab8XKP0+R1nq1yc91l\n/FovZom2jdZaZxG/P+bJ85gOMuUv8eKX1lrrzHPnsegN40PdXKnNYh7/bqtkWc/6YpCaW82m4ZlH\n67mimdla/OyXa6lVbbCZO4+Tk/h5DFfL1K4rd66HZ9b7ifv3jHijB4DCBD0AFCboAaAwQQ8AhQl6\nAChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91wYzM111sfhWeme0epXZlW\ns5vb8c/XWmv/bD/XrPXu3uPwzKMHn6R2HYwPwjNHy1z71Gk39z/uYLkKz8xXuba27ir+8zzu5Nra\nTlbxuX7yPWE5yV2z5SR+D3eS7XUtcZ1P+7nrvEw05bXW2nHmM65NUrtaN/7d1ge5+rrlIt5C11pr\nm8v4d3vt2lZq18Vh/OxPnueaA3Of8Hd5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QA\nUJigB4DCBD0AFCboAaAwQQ8AhZUttWndXmqs0xmEZ/obqVXttDsLzwwSZQqttXbnRq4M5+PP4gUT\n08lxatdiGd+1N88VYDzr5G79rV78vuqscteskyio2c/1xbRH03hpSbeTe0/oJQp0srJvMoMWv86P\nl/Hfc2ut7bdcGc5R4lrfSpb8bCcKuHq7h6ld1/rrqbmv3b4ennn1du7hPRrHi8wmybIepTYAwP+X\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhdVtr1vm\n/oeZjE/CM9k2rk6iSWo1zTVkndvcTM3tnI83Lu0+fZLadfgoPrffy13nHySbxi4miujOJxoRW2tt\nM9FeN+vmmvIO5vG502TrWra7rteNX+thom2wtdZGqU+Z29Xv5CoHR4lrvZzNU7umi/h5bCTvjwvn\ncp+xzQ7CI0cvcmd/cD7+m+7Mc8+cndTU7/JGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrFMtfitUrMdZINasP+MDyzGucakFruONrVzfhn\n/Ok7f5/a9fzB0/DMvJO7hZ8mO9QO5vE2v9Ei2U6W+IhryXtxNYxf526iTa611jqJVr7WWuv3441h\ni1WynWwR/53N57m2tlXyMw4zx59sr1sm7qtuP/fQWbbcM27vaC8801vlzmOtuxWe6Sz/cHHrjR4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21KY7iBdg\ntNbaINHD0EkWxnR6ieNf5IozFsdHqbkbW6PwzOVB7jMOTsfhmfPLXEHKaSf3P243MTfv50pLjpfx\nuXHyXmyJEpfePLeskywU6iYKhVarZLlVJ372uW/V2qDTy80lnh8byfv+XGJss5N8DuTGWmvxwcn4\nOLUp8zgddePP0rPijR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJig\nB4DCBD0AFCboAaCwuu11/dxX660S//uscu1kLdVel2vl63dz3VrnOvHGsD9762Zq1/5JfNfPPnmW\n2vVsMk/NnS7jbWiTZK/ZMnF/LJP/uy8S36ubrG3sJGveut1sNV9cL9Hy1k9+vI1u7lk16safBVv9\n3OFvdePPuMvJdBklb5BBi/+mh8l7arWI7zpNtHOeFW/0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwsqU2bbieHIyXFXRWyTaLRPHOfD5LrVomL3WmvOHG\nKLWq/eWXb4Vnrg1yhUIfPD5IzT0+jp//i3mupON02QvPTJK34rwTv86rRPFLa611e/Hv1VprvcRc\nsj+nDRIlP/1kt9VmptyqtbaWOP+1Tu5Dnu8twjMXkwU6m73cfbU+iJ9jP3crttks/hw46cTP8Kx4\noweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6ACis\ns8o2rwEA/+R5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/xfkBwlHN40TWAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28b83f3c518>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return x / np.linalg.norm(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(10))\n",
    "    return label_binarizer.transform(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = [None]\n",
    "    shape.extend(list(image_shape))\n",
    "    return tf.placeholder(shape=shape, dtype=tf.float32, name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(shape=[None, n_classes], dtype=tf.float32, name=\"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(dtype=tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal(\n",
    "        [conv_ksize[0], conv_ksize[1], int(x_tensor.shape[3]), conv_num_outputs]))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    conv_layer = tf.nn.conv2d(x_tensor,\n",
    "                              weight,\n",
    "                              strides=[1, conv_strides[0], conv_strides[1] ,1],\n",
    "                              padding='SAME')\n",
    "    \n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    conv_layer = tf.nn.max_pool(\n",
    "        conv_layer,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1] ,1],\n",
    "        padding='SAME'\n",
    "        )\n",
    "    \n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, \n",
    "                                             num_outputs, \n",
    "                                             weights_initializer=tf.truncated_normal_initializer(stddev=0.01))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn=None)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    cov_maxpool_layer_1 = conv2d_maxpool(x, \n",
    "                                         32,\n",
    "                                         conv_ksize=(5, 5), \n",
    "                                         conv_strides=(1, 1), \n",
    "                                         pool_ksize=(3, 3), \n",
    "                                         pool_strides=(2, 2))\n",
    "    \n",
    "    cov_maxpool_layer_2 = conv2d_maxpool(cov_maxpool_layer_1, \n",
    "                                         32,\n",
    "                                         conv_ksize=(5, 5), \n",
    "                                         conv_strides=(1, 1), \n",
    "                                         pool_ksize=(3, 3), \n",
    "                                         pool_strides=(2, 2))\n",
    "    '''\n",
    "    cov_maxpool_layer_3 = conv2d_maxpool(cov_maxpool_layer_2, \n",
    "                                         32,\n",
    "                                         conv_ksize=(5, 5), \n",
    "                                         conv_strides=(1, 1), \n",
    "                                         pool_ksize=(3, 3), \n",
    "                                         pool_strides=(2, 2))\n",
    "    '''\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten_layer = flatten(cov_maxpool_layer_2)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fully_conn_layer_1 = fully_conn(flatten_layer, 1024)\n",
    "    fully_conn_layer_1 = tf.nn.dropout(fully_conn_layer_1, keep_prob)\n",
    "    \n",
    "\n",
    "    fully_conn_layer_2 = fully_conn(fully_conn_layer_1, 512)\n",
    "    fully_conn_layer_2 = tf.nn.dropout(fully_conn_layer_2, keep_prob)\n",
    "\n",
    "    '''\n",
    "    fully_conn_layer_3 = fully_conn(fully_conn_layer_2, 32)\n",
    "    fully_conn_layer_3 = tf.nn.dropout(fully_conn_layer_3, keep_prob)\n",
    "    '''\n",
    "\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    output_layer = output(fully_conn_layer_2, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output_layer\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={keep_prob: keep_probability,\n",
    "                                       x: feature_batch,\n",
    "                                       y: label_batch})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(\"cost is:\",\n",
    "          session.run(cost, feed_dict={keep_prob: 1.0,\n",
    "                                       x: feature_batch,\n",
    "                                       y: label_batch}))\n",
    "    print(\"accuracy is:\",\n",
    "          session.run(accuracy, feed_dict={keep_prob: 1.0,\n",
    "                                           x: valid_features,\n",
    "                                           y: valid_labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  cost is: 2.20276\n",
      "accuracy is: 0.221\n",
      "Epoch  2, CIFAR-10 Batch 1:  cost is: 2.09625\n",
      "accuracy is: 0.2232\n",
      "Epoch  3, CIFAR-10 Batch 1:  cost is: 2.06897\n",
      "accuracy is: 0.2436\n",
      "Epoch  4, CIFAR-10 Batch 1:  cost is: 1.98017\n",
      "accuracy is: 0.3216\n",
      "Epoch  5, CIFAR-10 Batch 1:  cost is: 1.94424\n",
      "accuracy is: 0.3226\n",
      "Epoch  6, CIFAR-10 Batch 1:  cost is: 1.88792\n",
      "accuracy is: 0.3208\n",
      "Epoch  7, CIFAR-10 Batch 1:  cost is: 1.78297\n",
      "accuracy is: 0.3562\n",
      "Epoch  8, CIFAR-10 Batch 1:  cost is: 1.70649\n",
      "accuracy is: 0.3566\n",
      "Epoch  9, CIFAR-10 Batch 1:  cost is: 1.68741\n",
      "accuracy is: 0.3782\n",
      "Epoch 10, CIFAR-10 Batch 1:  cost is: 1.57644\n",
      "accuracy is: 0.3748\n",
      "Epoch 11, CIFAR-10 Batch 1:  cost is: 1.5171\n",
      "accuracy is: 0.3798\n",
      "Epoch 12, CIFAR-10 Batch 1:  cost is: 1.43265\n",
      "accuracy is: 0.3776\n",
      "Epoch 13, CIFAR-10 Batch 1:  cost is: 1.36422\n",
      "accuracy is: 0.4206\n",
      "Epoch 14, CIFAR-10 Batch 1:  cost is: 1.31224\n",
      "accuracy is: 0.4216\n",
      "Epoch 15, CIFAR-10 Batch 1:  cost is: 1.28251\n",
      "accuracy is: 0.403\n",
      "Epoch 16, CIFAR-10 Batch 1:  cost is: 1.2391\n",
      "accuracy is: 0.4308\n",
      "Epoch 17, CIFAR-10 Batch 1:  cost is: 1.14856\n",
      "accuracy is: 0.4278\n",
      "Epoch 18, CIFAR-10 Batch 1:  cost is: 1.16233\n",
      "accuracy is: 0.4396\n",
      "Epoch 19, CIFAR-10 Batch 1:  cost is: 1.09717\n",
      "accuracy is: 0.4482\n",
      "Epoch 20, CIFAR-10 Batch 1:  cost is: 1.04035\n",
      "accuracy is: 0.453\n",
      "Epoch 21, CIFAR-10 Batch 1:  cost is: 0.990854\n",
      "accuracy is: 0.451\n",
      "Epoch 22, CIFAR-10 Batch 1:  cost is: 0.953232\n",
      "accuracy is: 0.4522\n",
      "Epoch 23, CIFAR-10 Batch 1:  cost is: 0.904837\n",
      "accuracy is: 0.4644\n",
      "Epoch 24, CIFAR-10 Batch 1:  cost is: 0.869369\n",
      "accuracy is: 0.4566\n",
      "Epoch 25, CIFAR-10 Batch 1:  cost is: 0.794405\n",
      "accuracy is: 0.458\n",
      "Epoch 26, CIFAR-10 Batch 1:  cost is: 0.75184\n",
      "accuracy is: 0.476\n",
      "Epoch 27, CIFAR-10 Batch 1:  cost is: 0.790068\n",
      "accuracy is: 0.4718\n",
      "Epoch 28, CIFAR-10 Batch 1:  cost is: 0.748471\n",
      "accuracy is: 0.4588\n",
      "Epoch 29, CIFAR-10 Batch 1:  cost is: 0.625837\n",
      "accuracy is: 0.4738\n",
      "Epoch 30, CIFAR-10 Batch 1:  cost is: 0.629796\n",
      "accuracy is: 0.48\n",
      "Epoch 31, CIFAR-10 Batch 1:  cost is: 0.634541\n",
      "accuracy is: 0.4884\n",
      "Epoch 32, CIFAR-10 Batch 1:  cost is: 0.625071\n",
      "accuracy is: 0.478\n",
      "Epoch 33, CIFAR-10 Batch 1:  cost is: 0.592561\n",
      "accuracy is: 0.4914\n",
      "Epoch 34, CIFAR-10 Batch 1:  cost is: 0.513312\n",
      "accuracy is: 0.4858\n",
      "Epoch 35, CIFAR-10 Batch 1:  cost is: 0.480747\n",
      "accuracy is: 0.482\n",
      "Epoch 36, CIFAR-10 Batch 1:  cost is: 0.560457\n",
      "accuracy is: 0.5042\n",
      "Epoch 37, CIFAR-10 Batch 1:  cost is: 0.471464\n",
      "accuracy is: 0.4856\n",
      "Epoch 38, CIFAR-10 Batch 1:  cost is: 0.44498\n",
      "accuracy is: 0.4884\n",
      "Epoch 39, CIFAR-10 Batch 1:  cost is: 0.42831\n",
      "accuracy is: 0.4968\n",
      "Epoch 40, CIFAR-10 Batch 1:  cost is: 0.485869\n",
      "accuracy is: 0.473\n",
      "Epoch 41, CIFAR-10 Batch 1:  cost is: 0.455763\n",
      "accuracy is: 0.5178\n",
      "Epoch 42, CIFAR-10 Batch 1:  cost is: 0.443519\n",
      "accuracy is: 0.4914\n",
      "Epoch 43, CIFAR-10 Batch 1:  cost is: 0.451215\n",
      "accuracy is: 0.4934\n",
      "Epoch 44, CIFAR-10 Batch 1:  cost is: 0.388088\n",
      "accuracy is: 0.5158\n",
      "Epoch 45, CIFAR-10 Batch 1:  cost is: 0.401269\n",
      "accuracy is: 0.5098\n",
      "Epoch 46, CIFAR-10 Batch 1:  cost is: 0.344492\n",
      "accuracy is: 0.5198\n",
      "Epoch 47, CIFAR-10 Batch 1:  cost is: 0.353651\n",
      "accuracy is: 0.527\n",
      "Epoch 48, CIFAR-10 Batch 1:  cost is: 0.319685\n",
      "accuracy is: 0.4988\n",
      "Epoch 49, CIFAR-10 Batch 1:  cost is: 0.293024\n",
      "accuracy is: 0.5204\n",
      "Epoch 50, CIFAR-10 Batch 1:  cost is: 0.296369\n",
      "accuracy is: 0.5032\n",
      "Epoch 51, CIFAR-10 Batch 1:  cost is: 0.277839\n",
      "accuracy is: 0.5298\n",
      "Epoch 52, CIFAR-10 Batch 1:  cost is: 0.247103\n",
      "accuracy is: 0.5132\n",
      "Epoch 53, CIFAR-10 Batch 1:  cost is: 0.249684\n",
      "accuracy is: 0.5084\n",
      "Epoch 54, CIFAR-10 Batch 1:  cost is: 0.221647\n",
      "accuracy is: 0.5132\n",
      "Epoch 55, CIFAR-10 Batch 1:  cost is: 0.211542\n",
      "accuracy is: 0.5326\n",
      "Epoch 56, CIFAR-10 Batch 1:  cost is: 0.19435\n",
      "accuracy is: 0.5356\n",
      "Epoch 57, CIFAR-10 Batch 1:  cost is: 0.200375\n",
      "accuracy is: 0.5344\n",
      "Epoch 58, CIFAR-10 Batch 1:  cost is: 0.183584\n",
      "accuracy is: 0.5334\n",
      "Epoch 59, CIFAR-10 Batch 1:  cost is: 0.174786\n",
      "accuracy is: 0.5238\n",
      "Epoch 60, CIFAR-10 Batch 1:  cost is: 0.180504\n",
      "accuracy is: 0.5326\n",
      "Epoch 61, CIFAR-10 Batch 1:  cost is: 0.187093\n",
      "accuracy is: 0.5154\n",
      "Epoch 62, CIFAR-10 Batch 1:  cost is: 0.158645\n",
      "accuracy is: 0.5388\n",
      "Epoch 63, CIFAR-10 Batch 1:  cost is: 0.160559\n",
      "accuracy is: 0.531\n",
      "Epoch 64, CIFAR-10 Batch 1:  cost is: 0.177638\n",
      "accuracy is: 0.5342\n",
      "Epoch 65, CIFAR-10 Batch 1:  cost is: 0.124976\n",
      "accuracy is: 0.5384\n",
      "Epoch 66, CIFAR-10 Batch 1:  cost is: 0.118766\n",
      "accuracy is: 0.5412\n",
      "Epoch 67, CIFAR-10 Batch 1:  cost is: 0.145312\n",
      "accuracy is: 0.5518\n",
      "Epoch 68, CIFAR-10 Batch 1:  cost is: 0.166232\n",
      "accuracy is: 0.54\n",
      "Epoch 69, CIFAR-10 Batch 1:  cost is: 0.119249\n",
      "accuracy is: 0.5468\n",
      "Epoch 70, CIFAR-10 Batch 1:  cost is: 0.125633\n",
      "accuracy is: 0.536\n",
      "Epoch 71, CIFAR-10 Batch 1:  cost is: 0.132208\n",
      "accuracy is: 0.5336\n",
      "Epoch 72, CIFAR-10 Batch 1:  cost is: 0.159571\n",
      "accuracy is: 0.5242\n",
      "Epoch 73, CIFAR-10 Batch 1:  cost is: 0.0895857\n",
      "accuracy is: 0.5282\n",
      "Epoch 74, CIFAR-10 Batch 1:  cost is: 0.0795807\n",
      "accuracy is: 0.535\n",
      "Epoch 75, CIFAR-10 Batch 1:  cost is: 0.0888961\n",
      "accuracy is: 0.537\n",
      "Epoch 76, CIFAR-10 Batch 1:  cost is: 0.0733828\n",
      "accuracy is: 0.5254\n",
      "Epoch 77, CIFAR-10 Batch 1:  cost is: 0.0889092\n",
      "accuracy is: 0.5384\n",
      "Epoch 78, CIFAR-10 Batch 1:  cost is: 0.107356\n",
      "accuracy is: 0.5358\n",
      "Epoch 79, CIFAR-10 Batch 1:  cost is: 0.0953886\n",
      "accuracy is: 0.524\n",
      "Epoch 80, CIFAR-10 Batch 1:  cost is: 0.0849778\n",
      "accuracy is: 0.5404\n",
      "Epoch 81, CIFAR-10 Batch 1:  cost is: 0.0742073\n",
      "accuracy is: 0.5146\n",
      "Epoch 82, CIFAR-10 Batch 1:  cost is: 0.0824893\n",
      "accuracy is: 0.5062\n",
      "Epoch 83, CIFAR-10 Batch 1:  cost is: 0.0914495\n",
      "accuracy is: 0.5066\n",
      "Epoch 84, CIFAR-10 Batch 1:  cost is: 0.0855602\n",
      "accuracy is: 0.509\n",
      "Epoch 85, CIFAR-10 Batch 1:  cost is: 0.0866745\n",
      "accuracy is: 0.5026\n",
      "Epoch 86, CIFAR-10 Batch 1:  cost is: 0.059537\n",
      "accuracy is: 0.52\n",
      "Epoch 87, CIFAR-10 Batch 1:  cost is: 0.0833836\n",
      "accuracy is: 0.5016\n",
      "Epoch 88, CIFAR-10 Batch 1:  cost is: 0.0943979\n",
      "accuracy is: 0.504\n",
      "Epoch 89, CIFAR-10 Batch 1:  cost is: 0.106402\n",
      "accuracy is: 0.4996\n",
      "Epoch 90, CIFAR-10 Batch 1:  cost is: 0.0621936\n",
      "accuracy is: 0.5282\n",
      "Epoch 91, CIFAR-10 Batch 1:  cost is: 0.056725\n",
      "accuracy is: 0.531\n",
      "Epoch 92, CIFAR-10 Batch 1:  cost is: 0.0584087\n",
      "accuracy is: 0.5366\n",
      "Epoch 93, CIFAR-10 Batch 1:  cost is: 0.045135\n",
      "accuracy is: 0.5464\n",
      "Epoch 94, CIFAR-10 Batch 1:  cost is: 0.0418622\n",
      "accuracy is: 0.521\n",
      "Epoch 95, CIFAR-10 Batch 1:  cost is: 0.0425732\n",
      "accuracy is: 0.532\n",
      "Epoch 96, CIFAR-10 Batch 1:  cost is: 0.0360601\n",
      "accuracy is: 0.5376\n",
      "Epoch 97, CIFAR-10 Batch 1:  cost is: 0.0351773\n",
      "accuracy is: 0.5318\n",
      "Epoch 98, CIFAR-10 Batch 1:  cost is: 0.0289165\n",
      "accuracy is: 0.5376\n",
      "Epoch 99, CIFAR-10 Batch 1:  cost is: 0.0323643\n",
      "accuracy is: 0.5276\n",
      "Epoch 100, CIFAR-10 Batch 1:  cost is: 0.0218035\n",
      "accuracy is: 0.542\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  cost is: 2.24145\n",
      "accuracy is: 0.2354\n",
      "Epoch  1, CIFAR-10 Batch 2:  cost is: 2.09147\n",
      "accuracy is: 0.2426\n",
      "Epoch  1, CIFAR-10 Batch 3:  cost is: 1.74217\n",
      "accuracy is: 0.2874\n",
      "Epoch  1, CIFAR-10 Batch 4:  cost is: 1.79113\n",
      "accuracy is: 0.3528\n",
      "Epoch  1, CIFAR-10 Batch 5:  cost is: 1.76673\n",
      "accuracy is: 0.3078\n",
      "Epoch  2, CIFAR-10 Batch 1:  cost is: 1.87996\n",
      "accuracy is: 0.3496\n",
      "Epoch  2, CIFAR-10 Batch 2:  cost is: 1.66192\n",
      "accuracy is: 0.3932\n",
      "Epoch  2, CIFAR-10 Batch 3:  cost is: 1.40075\n",
      "accuracy is: 0.3658\n",
      "Epoch  2, CIFAR-10 Batch 4:  cost is: 1.59135\n",
      "accuracy is: 0.4314\n",
      "Epoch  2, CIFAR-10 Batch 5:  cost is: 1.57687\n",
      "accuracy is: 0.4086\n",
      "Epoch  3, CIFAR-10 Batch 1:  cost is: 1.68385\n",
      "accuracy is: 0.4004\n",
      "Epoch  3, CIFAR-10 Batch 2:  cost is: 1.44662\n",
      "accuracy is: 0.425\n",
      "Epoch  3, CIFAR-10 Batch 3:  cost is: 1.39328\n",
      "accuracy is: 0.3828\n",
      "Epoch  3, CIFAR-10 Batch 4:  cost is: 1.41088\n",
      "accuracy is: 0.4462\n",
      "Epoch  3, CIFAR-10 Batch 5:  cost is: 1.50893\n",
      "accuracy is: 0.4086\n",
      "Epoch  4, CIFAR-10 Batch 1:  cost is: 1.52545\n",
      "accuracy is: 0.4344\n",
      "Epoch  4, CIFAR-10 Batch 2:  cost is: 1.32029\n",
      "accuracy is: 0.4208\n",
      "Epoch  4, CIFAR-10 Batch 3:  cost is: 1.26198\n",
      "accuracy is: 0.4436\n",
      "Epoch  4, CIFAR-10 Batch 4:  cost is: 1.33507\n",
      "accuracy is: 0.4698\n",
      "Epoch  4, CIFAR-10 Batch 5:  cost is: 1.39767\n",
      "accuracy is: 0.4476\n",
      "Epoch  5, CIFAR-10 Batch 1:  cost is: 1.37596\n",
      "accuracy is: 0.4442\n",
      "Epoch  5, CIFAR-10 Batch 2:  cost is: 1.22439\n",
      "accuracy is: 0.4658\n",
      "Epoch  5, CIFAR-10 Batch 3:  cost is: 1.18637\n",
      "accuracy is: 0.4748\n",
      "Epoch  5, CIFAR-10 Batch 4:  cost is: 1.26839\n",
      "accuracy is: 0.4802\n",
      "Epoch  5, CIFAR-10 Batch 5:  cost is: 1.29185\n",
      "accuracy is: 0.4602\n",
      "Epoch  6, CIFAR-10 Batch 1:  cost is: 1.25966\n",
      "accuracy is: 0.4688\n",
      "Epoch  6, CIFAR-10 Batch 2:  cost is: 1.13227\n",
      "accuracy is: 0.4952\n",
      "Epoch  6, CIFAR-10 Batch 3:  cost is: 1.03059\n",
      "accuracy is: 0.4792\n",
      "Epoch  6, CIFAR-10 Batch 4:  cost is: 1.16789\n",
      "accuracy is: 0.4912\n",
      "Epoch  6, CIFAR-10 Batch 5:  cost is: 1.20642\n",
      "accuracy is: 0.507\n",
      "Epoch  7, CIFAR-10 Batch 1:  cost is: 1.18809\n",
      "accuracy is: 0.4616\n",
      "Epoch  7, CIFAR-10 Batch 2:  cost is: 1.12343\n",
      "accuracy is: 0.4538\n",
      "Epoch  7, CIFAR-10 Batch 3:  cost is: 1.02166\n",
      "accuracy is: 0.5112\n",
      "Epoch  7, CIFAR-10 Batch 4:  cost is: 1.0903\n",
      "accuracy is: 0.496\n",
      "Epoch  7, CIFAR-10 Batch 5:  cost is: 1.10735\n",
      "accuracy is: 0.5072\n",
      "Epoch  8, CIFAR-10 Batch 1:  cost is: 1.08715\n",
      "accuracy is: 0.5036\n",
      "Epoch  8, CIFAR-10 Batch 2:  cost is: 1.04008\n",
      "accuracy is: 0.486\n",
      "Epoch  8, CIFAR-10 Batch 3:  cost is: 0.914743\n",
      "accuracy is: 0.5288\n",
      "Epoch  8, CIFAR-10 Batch 4:  cost is: 1.04872\n",
      "accuracy is: 0.522\n",
      "Epoch  8, CIFAR-10 Batch 5:  cost is: 1.05627\n",
      "accuracy is: 0.5044\n",
      "Epoch  9, CIFAR-10 Batch 1:  cost is: 1.01808\n",
      "accuracy is: 0.4882\n",
      "Epoch  9, CIFAR-10 Batch 2:  cost is: 0.988759\n",
      "accuracy is: 0.5028\n",
      "Epoch  9, CIFAR-10 Batch 3:  cost is: 0.8459\n",
      "accuracy is: 0.5104\n",
      "Epoch  9, CIFAR-10 Batch 4:  cost is: 0.980624\n",
      "accuracy is: 0.5282\n",
      "Epoch  9, CIFAR-10 Batch 5:  cost is: 0.923463\n",
      "accuracy is: 0.5198\n",
      "Epoch 10, CIFAR-10 Batch 1:  cost is: 0.979192\n",
      "accuracy is: 0.5142\n",
      "Epoch 10, CIFAR-10 Batch 2:  cost is: 0.88469\n",
      "accuracy is: 0.5384\n",
      "Epoch 10, CIFAR-10 Batch 3:  cost is: 0.807378\n",
      "accuracy is: 0.549\n",
      "Epoch 10, CIFAR-10 Batch 4:  cost is: 0.85423\n",
      "accuracy is: 0.5576\n",
      "Epoch 10, CIFAR-10 Batch 5:  cost is: 0.858245\n",
      "accuracy is: 0.5452\n",
      "Epoch 11, CIFAR-10 Batch 1:  cost is: 1.0186\n",
      "accuracy is: 0.5026\n",
      "Epoch 11, CIFAR-10 Batch 2:  cost is: 0.902372\n",
      "accuracy is: 0.5338\n",
      "Epoch 11, CIFAR-10 Batch 3:  cost is: 0.764933\n",
      "accuracy is: 0.5466\n",
      "Epoch 11, CIFAR-10 Batch 4:  cost is: 0.759194\n",
      "accuracy is: 0.54\n",
      "Epoch 11, CIFAR-10 Batch 5:  cost is: 0.764339\n",
      "accuracy is: 0.5548\n",
      "Epoch 12, CIFAR-10 Batch 1:  cost is: 0.875676\n",
      "accuracy is: 0.5134\n",
      "Epoch 12, CIFAR-10 Batch 2:  cost is: 0.843754\n",
      "accuracy is: 0.5386\n",
      "Epoch 12, CIFAR-10 Batch 3:  cost is: 0.710929\n",
      "accuracy is: 0.551\n",
      "Epoch 12, CIFAR-10 Batch 4:  cost is: 0.738656\n",
      "accuracy is: 0.5488\n",
      "Epoch 12, CIFAR-10 Batch 5:  cost is: 0.70635\n",
      "accuracy is: 0.576\n",
      "Epoch 13, CIFAR-10 Batch 1:  cost is: 0.843397\n",
      "accuracy is: 0.5372\n",
      "Epoch 13, CIFAR-10 Batch 2:  cost is: 0.753202\n",
      "accuracy is: 0.56\n",
      "Epoch 13, CIFAR-10 Batch 3:  cost is: 0.710383\n",
      "accuracy is: 0.5428\n",
      "Epoch 13, CIFAR-10 Batch 4:  cost is: 0.755929\n",
      "accuracy is: 0.5578\n",
      "Epoch 13, CIFAR-10 Batch 5:  cost is: 0.675851\n",
      "accuracy is: 0.567\n",
      "Epoch 14, CIFAR-10 Batch 1:  cost is: 0.765686\n",
      "accuracy is: 0.5398\n",
      "Epoch 14, CIFAR-10 Batch 2:  cost is: 0.713816\n",
      "accuracy is: 0.5654\n",
      "Epoch 14, CIFAR-10 Batch 3:  cost is: 0.602839\n",
      "accuracy is: 0.5484\n",
      "Epoch 14, CIFAR-10 Batch 4:  cost is: 0.655834\n",
      "accuracy is: 0.5772\n",
      "Epoch 14, CIFAR-10 Batch 5:  cost is: 0.612513\n",
      "accuracy is: 0.5738\n",
      "Epoch 15, CIFAR-10 Batch 1:  cost is: 0.766042\n",
      "accuracy is: 0.5622\n",
      "Epoch 15, CIFAR-10 Batch 2:  cost is: 0.739619\n",
      "accuracy is: 0.5582\n",
      "Epoch 15, CIFAR-10 Batch 3:  cost is: 0.573233\n",
      "accuracy is: 0.5796\n",
      "Epoch 15, CIFAR-10 Batch 4:  cost is: 0.582684\n",
      "accuracy is: 0.573\n",
      "Epoch 15, CIFAR-10 Batch 5:  cost is: 0.552554\n",
      "accuracy is: 0.585\n",
      "Epoch 16, CIFAR-10 Batch 1:  cost is: 0.812424\n",
      "accuracy is: 0.5592\n",
      "Epoch 16, CIFAR-10 Batch 2:  cost is: 0.699331\n",
      "accuracy is: 0.5772\n",
      "Epoch 16, CIFAR-10 Batch 3:  cost is: 0.519062\n",
      "accuracy is: 0.5678\n",
      "Epoch 16, CIFAR-10 Batch 4:  cost is: 0.571716\n",
      "accuracy is: 0.5882\n",
      "Epoch 16, CIFAR-10 Batch 5:  cost is: 0.501706\n",
      "accuracy is: 0.574\n",
      "Epoch 17, CIFAR-10 Batch 1:  cost is: 0.677359\n",
      "accuracy is: 0.5742\n",
      "Epoch 17, CIFAR-10 Batch 2:  cost is: 0.628085\n",
      "accuracy is: 0.5822\n",
      "Epoch 17, CIFAR-10 Batch 3:  cost is: 0.449329\n",
      "accuracy is: 0.5786\n",
      "Epoch 17, CIFAR-10 Batch 4:  cost is: 0.540233\n",
      "accuracy is: 0.5888\n",
      "Epoch 17, CIFAR-10 Batch 5:  cost is: 0.464326\n",
      "accuracy is: 0.5826\n",
      "Epoch 18, CIFAR-10 Batch 1:  cost is: 0.63187\n",
      "accuracy is: 0.5836\n",
      "Epoch 18, CIFAR-10 Batch 2:  cost is: 0.579611\n",
      "accuracy is: 0.5958\n",
      "Epoch 18, CIFAR-10 Batch 3:  cost is: 0.39559\n",
      "accuracy is: 0.5788\n",
      "Epoch 18, CIFAR-10 Batch 4:  cost is: 0.49247\n",
      "accuracy is: 0.579\n",
      "Epoch 18, CIFAR-10 Batch 5:  cost is: 0.42673\n",
      "accuracy is: 0.5874\n",
      "Epoch 19, CIFAR-10 Batch 1:  cost is: 0.592881\n",
      "accuracy is: 0.5814\n",
      "Epoch 19, CIFAR-10 Batch 2:  cost is: 0.566716\n",
      "accuracy is: 0.5828\n",
      "Epoch 19, CIFAR-10 Batch 3:  cost is: 0.403148\n",
      "accuracy is: 0.584\n",
      "Epoch 19, CIFAR-10 Batch 4:  cost is: 0.425754\n",
      "accuracy is: 0.5936\n",
      "Epoch 19, CIFAR-10 Batch 5:  cost is: 0.412507\n",
      "accuracy is: 0.6008\n",
      "Epoch 20, CIFAR-10 Batch 1:  cost is: 0.588909\n",
      "accuracy is: 0.5876\n",
      "Epoch 20, CIFAR-10 Batch 2:  cost is: 0.488699\n",
      "accuracy is: 0.6048\n",
      "Epoch 20, CIFAR-10 Batch 3:  cost is: 0.414007\n",
      "accuracy is: 0.5908\n",
      "Epoch 20, CIFAR-10 Batch 4:  cost is: 0.426896\n",
      "accuracy is: 0.6024\n",
      "Epoch 20, CIFAR-10 Batch 5:  cost is: 0.403391\n",
      "accuracy is: 0.6112\n",
      "Epoch 21, CIFAR-10 Batch 1:  cost is: 0.5158\n",
      "accuracy is: 0.605\n",
      "Epoch 21, CIFAR-10 Batch 2:  cost is: 0.474261\n",
      "accuracy is: 0.5792\n",
      "Epoch 21, CIFAR-10 Batch 3:  cost is: 0.377675\n",
      "accuracy is: 0.6184\n",
      "Epoch 21, CIFAR-10 Batch 4:  cost is: 0.437403\n",
      "accuracy is: 0.5952\n",
      "Epoch 21, CIFAR-10 Batch 5:  cost is: 0.350777\n",
      "accuracy is: 0.5962\n",
      "Epoch 22, CIFAR-10 Batch 1:  cost is: 0.490753\n",
      "accuracy is: 0.609\n",
      "Epoch 22, CIFAR-10 Batch 2:  cost is: 0.417301\n",
      "accuracy is: 0.5876\n",
      "Epoch 22, CIFAR-10 Batch 3:  cost is: 0.304443\n",
      "accuracy is: 0.6062\n",
      "Epoch 22, CIFAR-10 Batch 4:  cost is: 0.38133\n",
      "accuracy is: 0.6\n",
      "Epoch 22, CIFAR-10 Batch 5:  cost is: 0.380821\n",
      "accuracy is: 0.5922\n",
      "Epoch 23, CIFAR-10 Batch 1:  cost is: 0.484907\n",
      "accuracy is: 0.6018\n",
      "Epoch 23, CIFAR-10 Batch 2:  cost is: 0.388511\n",
      "accuracy is: 0.6018\n",
      "Epoch 23, CIFAR-10 Batch 3:  cost is: 0.301776\n",
      "accuracy is: 0.5872\n",
      "Epoch 23, CIFAR-10 Batch 4:  cost is: 0.397693\n",
      "accuracy is: 0.606\n",
      "Epoch 23, CIFAR-10 Batch 5:  cost is: 0.336703\n",
      "accuracy is: 0.5978\n",
      "Epoch 24, CIFAR-10 Batch 1:  cost is: 0.447246\n",
      "accuracy is: 0.6096\n",
      "Epoch 24, CIFAR-10 Batch 2:  cost is: 0.371361\n",
      "accuracy is: 0.5988\n",
      "Epoch 24, CIFAR-10 Batch 3:  cost is: 0.264955\n",
      "accuracy is: 0.5946\n",
      "Epoch 24, CIFAR-10 Batch 4:  cost is: 0.373724\n",
      "accuracy is: 0.601\n",
      "Epoch 24, CIFAR-10 Batch 5:  cost is: 0.294402\n",
      "accuracy is: 0.5894\n",
      "Epoch 25, CIFAR-10 Batch 1:  cost is: 0.43393\n",
      "accuracy is: 0.5882\n",
      "Epoch 25, CIFAR-10 Batch 2:  cost is: 0.348134\n",
      "accuracy is: 0.5986\n",
      "Epoch 25, CIFAR-10 Batch 3:  cost is: 0.28497\n",
      "accuracy is: 0.5896\n",
      "Epoch 25, CIFAR-10 Batch 4:  cost is: 0.363314\n",
      "accuracy is: 0.597\n",
      "Epoch 25, CIFAR-10 Batch 5:  cost is: 0.273106\n",
      "accuracy is: 0.5968\n",
      "Epoch 26, CIFAR-10 Batch 1:  cost is: 0.366161\n",
      "accuracy is: 0.6012\n",
      "Epoch 26, CIFAR-10 Batch 2:  cost is: 0.314103\n",
      "accuracy is: 0.6116\n",
      "Epoch 26, CIFAR-10 Batch 3:  cost is: 0.304956\n",
      "accuracy is: 0.6092\n",
      "Epoch 26, CIFAR-10 Batch 4:  cost is: 0.315832\n",
      "accuracy is: 0.619\n",
      "Epoch 26, CIFAR-10 Batch 5:  cost is: 0.249694\n",
      "accuracy is: 0.6084\n",
      "Epoch 27, CIFAR-10 Batch 1:  cost is: 0.36277\n",
      "accuracy is: 0.617\n",
      "Epoch 27, CIFAR-10 Batch 2:  cost is: 0.379083\n",
      "accuracy is: 0.5828\n",
      "Epoch 27, CIFAR-10 Batch 3:  cost is: 0.297977\n",
      "accuracy is: 0.6242\n",
      "Epoch 27, CIFAR-10 Batch 4:  cost is: 0.27371\n",
      "accuracy is: 0.628\n",
      "Epoch 27, CIFAR-10 Batch 5:  cost is: 0.243572\n",
      "accuracy is: 0.6202\n",
      "Epoch 28, CIFAR-10 Batch 1:  cost is: 0.367698\n",
      "accuracy is: 0.625\n",
      "Epoch 28, CIFAR-10 Batch 2:  cost is: 0.269833\n",
      "accuracy is: 0.6106\n",
      "Epoch 28, CIFAR-10 Batch 3:  cost is: 0.248121\n",
      "accuracy is: 0.6212\n",
      "Epoch 28, CIFAR-10 Batch 4:  cost is: 0.268725\n",
      "accuracy is: 0.6038\n",
      "Epoch 28, CIFAR-10 Batch 5:  cost is: 0.222847\n",
      "accuracy is: 0.6126\n",
      "Epoch 29, CIFAR-10 Batch 1:  cost is: 0.347006\n",
      "accuracy is: 0.6256\n",
      "Epoch 29, CIFAR-10 Batch 2:  cost is: 0.283529\n",
      "accuracy is: 0.6074\n",
      "Epoch 29, CIFAR-10 Batch 3:  cost is: 0.235267\n",
      "accuracy is: 0.6212\n",
      "Epoch 29, CIFAR-10 Batch 4:  cost is: 0.243086\n",
      "accuracy is: 0.6306\n",
      "Epoch 29, CIFAR-10 Batch 5:  cost is: 0.233681\n",
      "accuracy is: 0.6124\n",
      "Epoch 30, CIFAR-10 Batch 1:  cost is: 0.327939\n",
      "accuracy is: 0.6302\n",
      "Epoch 30, CIFAR-10 Batch 2:  cost is: 0.279211\n",
      "accuracy is: 0.6126\n",
      "Epoch 30, CIFAR-10 Batch 3:  cost is: 0.229151\n",
      "accuracy is: 0.6174\n",
      "Epoch 30, CIFAR-10 Batch 4:  cost is: 0.258697\n",
      "accuracy is: 0.634\n",
      "Epoch 30, CIFAR-10 Batch 5:  cost is: 0.237303\n",
      "accuracy is: 0.5984\n",
      "Epoch 31, CIFAR-10 Batch 1:  cost is: 0.313195\n",
      "accuracy is: 0.6326\n",
      "Epoch 31, CIFAR-10 Batch 2:  cost is: 0.249141\n",
      "accuracy is: 0.616\n",
      "Epoch 31, CIFAR-10 Batch 3:  cost is: 0.185027\n",
      "accuracy is: 0.6326\n",
      "Epoch 31, CIFAR-10 Batch 4:  cost is: 0.223116\n",
      "accuracy is: 0.6268\n",
      "Epoch 31, CIFAR-10 Batch 5:  cost is: 0.184116\n",
      "accuracy is: 0.6132\n",
      "Epoch 32, CIFAR-10 Batch 1:  cost is: 0.26126\n",
      "accuracy is: 0.6424\n",
      "Epoch 32, CIFAR-10 Batch 2:  cost is: 0.298726\n",
      "accuracy is: 0.5978\n",
      "Epoch 32, CIFAR-10 Batch 3:  cost is: 0.217125\n",
      "accuracy is: 0.6258\n",
      "Epoch 32, CIFAR-10 Batch 4:  cost is: 0.220423\n",
      "accuracy is: 0.6324\n",
      "Epoch 32, CIFAR-10 Batch 5:  cost is: 0.235797\n",
      "accuracy is: 0.5964\n",
      "Epoch 33, CIFAR-10 Batch 1:  cost is: 0.263758\n",
      "accuracy is: 0.6222\n",
      "Epoch 33, CIFAR-10 Batch 2:  cost is: 0.237405\n",
      "accuracy is: 0.6354\n",
      "Epoch 33, CIFAR-10 Batch 3:  cost is: 0.197471\n",
      "accuracy is: 0.636\n",
      "Epoch 33, CIFAR-10 Batch 4:  cost is: 0.206794\n",
      "accuracy is: 0.6304\n",
      "Epoch 33, CIFAR-10 Batch 5:  cost is: 0.171627\n",
      "accuracy is: 0.6146\n",
      "Epoch 34, CIFAR-10 Batch 1:  cost is: 0.266228\n",
      "accuracy is: 0.6132\n",
      "Epoch 34, CIFAR-10 Batch 2:  cost is: 0.237805\n",
      "accuracy is: 0.6228\n",
      "Epoch 34, CIFAR-10 Batch 3:  cost is: 0.141502\n",
      "accuracy is: 0.6358\n",
      "Epoch 34, CIFAR-10 Batch 4:  cost is: 0.218455\n",
      "accuracy is: 0.6364\n",
      "Epoch 34, CIFAR-10 Batch 5:  cost is: 0.151082\n",
      "accuracy is: 0.6338\n",
      "Epoch 35, CIFAR-10 Batch 1:  cost is: 0.209846\n",
      "accuracy is: 0.63\n",
      "Epoch 35, CIFAR-10 Batch 2:  cost is: 0.188952\n",
      "accuracy is: 0.639\n",
      "Epoch 35, CIFAR-10 Batch 3:  cost is: 0.153091\n",
      "accuracy is: 0.6302\n",
      "Epoch 35, CIFAR-10 Batch 4:  cost is: 0.167384\n",
      "accuracy is: 0.6302\n",
      "Epoch 35, CIFAR-10 Batch 5:  cost is: 0.170111\n",
      "accuracy is: 0.6358\n",
      "Epoch 36, CIFAR-10 Batch 1:  cost is: 0.215543\n",
      "accuracy is: 0.6432\n",
      "Epoch 36, CIFAR-10 Batch 2:  cost is: 0.176431\n",
      "accuracy is: 0.6404\n",
      "Epoch 36, CIFAR-10 Batch 3:  cost is: 0.152867\n",
      "accuracy is: 0.6378\n",
      "Epoch 36, CIFAR-10 Batch 4:  cost is: 0.186574\n",
      "accuracy is: 0.6314\n",
      "Epoch 36, CIFAR-10 Batch 5:  cost is: 0.163386\n",
      "accuracy is: 0.6378\n",
      "Epoch 37, CIFAR-10 Batch 1:  cost is: 0.254784\n",
      "accuracy is: 0.6094\n",
      "Epoch 37, CIFAR-10 Batch 2:  cost is: 0.200686\n",
      "accuracy is: 0.644\n",
      "Epoch 37, CIFAR-10 Batch 3:  cost is: 0.169299\n",
      "accuracy is: 0.632\n",
      "Epoch 37, CIFAR-10 Batch 4:  cost is: 0.172947\n",
      "accuracy is: 0.6292\n",
      "Epoch 37, CIFAR-10 Batch 5:  cost is: 0.157372\n",
      "accuracy is: 0.6162\n",
      "Epoch 38, CIFAR-10 Batch 1:  cost is: 0.17804\n",
      "accuracy is: 0.63\n",
      "Epoch 38, CIFAR-10 Batch 2:  cost is: 0.222874\n",
      "accuracy is: 0.6398\n",
      "Epoch 38, CIFAR-10 Batch 3:  cost is: 0.141173\n",
      "accuracy is: 0.6358\n",
      "Epoch 38, CIFAR-10 Batch 4:  cost is: 0.162249\n",
      "accuracy is: 0.644\n",
      "Epoch 38, CIFAR-10 Batch 5:  cost is: 0.142688\n",
      "accuracy is: 0.6488\n",
      "Epoch 39, CIFAR-10 Batch 1:  cost is: 0.172313\n",
      "accuracy is: 0.6302\n",
      "Epoch 39, CIFAR-10 Batch 2:  cost is: 0.181312\n",
      "accuracy is: 0.625\n",
      "Epoch 39, CIFAR-10 Batch 3:  cost is: 0.126902\n",
      "accuracy is: 0.6546\n",
      "Epoch 39, CIFAR-10 Batch 4:  cost is: 0.148844\n",
      "accuracy is: 0.6258\n",
      "Epoch 39, CIFAR-10 Batch 5:  cost is: 0.122985\n",
      "accuracy is: 0.6406\n",
      "Epoch 40, CIFAR-10 Batch 1:  cost is: 0.154637\n",
      "accuracy is: 0.6274\n",
      "Epoch 40, CIFAR-10 Batch 2:  cost is: 0.167512\n",
      "accuracy is: 0.6374\n",
      "Epoch 40, CIFAR-10 Batch 3:  cost is: 0.1298\n",
      "accuracy is: 0.6578\n",
      "Epoch 40, CIFAR-10 Batch 4:  cost is: 0.151558\n",
      "accuracy is: 0.6226\n",
      "Epoch 40, CIFAR-10 Batch 5:  cost is: 0.109079\n",
      "accuracy is: 0.6434\n",
      "Epoch 41, CIFAR-10 Batch 1:  cost is: 0.170277\n",
      "accuracy is: 0.6386\n",
      "Epoch 41, CIFAR-10 Batch 2:  cost is: 0.151376\n",
      "accuracy is: 0.6446\n",
      "Epoch 41, CIFAR-10 Batch 3:  cost is: 0.130767\n",
      "accuracy is: 0.6498\n",
      "Epoch 41, CIFAR-10 Batch 4:  cost is: 0.132128\n",
      "accuracy is: 0.6352\n",
      "Epoch 41, CIFAR-10 Batch 5:  cost is: 0.0821905\n",
      "accuracy is: 0.6362\n",
      "Epoch 42, CIFAR-10 Batch 1:  cost is: 0.139089\n",
      "accuracy is: 0.6442\n",
      "Epoch 42, CIFAR-10 Batch 2:  cost is: 0.138001\n",
      "accuracy is: 0.6378\n",
      "Epoch 42, CIFAR-10 Batch 3:  cost is: 0.124157\n",
      "accuracy is: 0.6332\n",
      "Epoch 42, CIFAR-10 Batch 4:  cost is: 0.143466\n",
      "accuracy is: 0.6334\n",
      "Epoch 42, CIFAR-10 Batch 5:  cost is: 0.0998155\n",
      "accuracy is: 0.632\n",
      "Epoch 43, CIFAR-10 Batch 1:  cost is: 0.135389\n",
      "accuracy is: 0.6416\n",
      "Epoch 43, CIFAR-10 Batch 2:  cost is: 0.133626\n",
      "accuracy is: 0.635\n",
      "Epoch 43, CIFAR-10 Batch 3:  cost is: 0.0948597\n",
      "accuracy is: 0.6428\n",
      "Epoch 43, CIFAR-10 Batch 4:  cost is: 0.131781\n",
      "accuracy is: 0.6214\n",
      "Epoch 43, CIFAR-10 Batch 5:  cost is: 0.0716396\n",
      "accuracy is: 0.6438\n",
      "Epoch 44, CIFAR-10 Batch 1:  cost is: 0.108908\n",
      "accuracy is: 0.644\n",
      "Epoch 44, CIFAR-10 Batch 2:  cost is: 0.0962161\n",
      "accuracy is: 0.6392\n",
      "Epoch 44, CIFAR-10 Batch 3:  cost is: 0.0782491\n",
      "accuracy is: 0.6428\n",
      "Epoch 44, CIFAR-10 Batch 4:  cost is: 0.104059\n",
      "accuracy is: 0.6352\n",
      "Epoch 44, CIFAR-10 Batch 5:  cost is: 0.0860893\n",
      "accuracy is: 0.6384\n",
      "Epoch 45, CIFAR-10 Batch 1:  cost is: 0.106651\n",
      "accuracy is: 0.6374\n",
      "Epoch 45, CIFAR-10 Batch 2:  cost is: 0.145692\n",
      "accuracy is: 0.6382\n",
      "Epoch 45, CIFAR-10 Batch 3:  cost is: 0.0794723\n",
      "accuracy is: 0.6544\n",
      "Epoch 45, CIFAR-10 Batch 4:  cost is: 0.114084\n",
      "accuracy is: 0.6296\n",
      "Epoch 45, CIFAR-10 Batch 5:  cost is: 0.0804178\n",
      "accuracy is: 0.647\n",
      "Epoch 46, CIFAR-10 Batch 1:  cost is: 0.114274\n",
      "accuracy is: 0.6488\n",
      "Epoch 46, CIFAR-10 Batch 2:  cost is: 0.126736\n",
      "accuracy is: 0.6392\n",
      "Epoch 46, CIFAR-10 Batch 3:  cost is: 0.0673263\n",
      "accuracy is: 0.658\n",
      "Epoch 46, CIFAR-10 Batch 4:  cost is: 0.1036\n",
      "accuracy is: 0.6432\n",
      "Epoch 46, CIFAR-10 Batch 5:  cost is: 0.0898873\n",
      "accuracy is: 0.624\n",
      "Epoch 47, CIFAR-10 Batch 1:  cost is: 0.108418\n",
      "accuracy is: 0.654\n",
      "Epoch 47, CIFAR-10 Batch 2:  cost is: 0.100022\n",
      "accuracy is: 0.655\n",
      "Epoch 47, CIFAR-10 Batch 3:  cost is: 0.0752873\n",
      "accuracy is: 0.6478\n",
      "Epoch 47, CIFAR-10 Batch 4:  cost is: 0.0982717\n",
      "accuracy is: 0.6398\n",
      "Epoch 47, CIFAR-10 Batch 5:  cost is: 0.0853317\n",
      "accuracy is: 0.621\n",
      "Epoch 48, CIFAR-10 Batch 1:  cost is: 0.0969121\n",
      "accuracy is: 0.648\n",
      "Epoch 48, CIFAR-10 Batch 2:  cost is: 0.0974743\n",
      "accuracy is: 0.6378\n",
      "Epoch 48, CIFAR-10 Batch 3:  cost is: 0.052218\n",
      "accuracy is: 0.6508\n",
      "Epoch 48, CIFAR-10 Batch 4:  cost is: 0.0759786\n",
      "accuracy is: 0.6468\n",
      "Epoch 48, CIFAR-10 Batch 5:  cost is: 0.0708084\n",
      "accuracy is: 0.6234\n",
      "Epoch 49, CIFAR-10 Batch 1:  cost is: 0.102179\n",
      "accuracy is: 0.6356\n",
      "Epoch 49, CIFAR-10 Batch 2:  cost is: 0.132074\n",
      "accuracy is: 0.6198\n",
      "Epoch 49, CIFAR-10 Batch 3:  cost is: 0.0587173\n",
      "accuracy is: 0.6572\n",
      "Epoch 49, CIFAR-10 Batch 4:  cost is: 0.122659\n",
      "accuracy is: 0.6384\n",
      "Epoch 49, CIFAR-10 Batch 5:  cost is: 0.0561752\n",
      "accuracy is: 0.6324\n",
      "Epoch 50, CIFAR-10 Batch 1:  cost is: 0.125459\n",
      "accuracy is: 0.6562\n",
      "Epoch 50, CIFAR-10 Batch 2:  cost is: 0.116672\n",
      "accuracy is: 0.6384\n",
      "Epoch 50, CIFAR-10 Batch 3:  cost is: 0.0634867\n",
      "accuracy is: 0.6618\n",
      "Epoch 50, CIFAR-10 Batch 4:  cost is: 0.121007\n",
      "accuracy is: 0.651\n",
      "Epoch 50, CIFAR-10 Batch 5:  cost is: 0.0733648\n",
      "accuracy is: 0.6344\n",
      "Epoch 51, CIFAR-10 Batch 1:  cost is: 0.122684\n",
      "accuracy is: 0.6446\n",
      "Epoch 51, CIFAR-10 Batch 2:  cost is: 0.0957691\n",
      "accuracy is: 0.6294\n",
      "Epoch 51, CIFAR-10 Batch 3:  cost is: 0.0785415\n",
      "accuracy is: 0.6374\n",
      "Epoch 51, CIFAR-10 Batch 4:  cost is: 0.109599\n",
      "accuracy is: 0.6334\n",
      "Epoch 51, CIFAR-10 Batch 5:  cost is: 0.0691962\n",
      "accuracy is: 0.6316\n",
      "Epoch 52, CIFAR-10 Batch 1:  cost is: 0.0894011\n",
      "accuracy is: 0.6348\n",
      "Epoch 52, CIFAR-10 Batch 2:  cost is: 0.104887\n",
      "accuracy is: 0.6568\n",
      "Epoch 52, CIFAR-10 Batch 3:  cost is: 0.066212\n",
      "accuracy is: 0.6402\n",
      "Epoch 52, CIFAR-10 Batch 4:  cost is: 0.0709074\n",
      "accuracy is: 0.6418\n",
      "Epoch 52, CIFAR-10 Batch 5:  cost is: 0.048899\n",
      "accuracy is: 0.6412\n",
      "Epoch 53, CIFAR-10 Batch 1:  cost is: 0.0925259\n",
      "accuracy is: 0.6516\n",
      "Epoch 53, CIFAR-10 Batch 2:  cost is: 0.11256\n",
      "accuracy is: 0.655\n",
      "Epoch 53, CIFAR-10 Batch 3:  cost is: 0.0698499\n",
      "accuracy is: 0.6378\n",
      "Epoch 53, CIFAR-10 Batch 4:  cost is: 0.0823416\n",
      "accuracy is: 0.6284\n",
      "Epoch 53, CIFAR-10 Batch 5:  cost is: 0.0640828\n",
      "accuracy is: 0.646\n",
      "Epoch 54, CIFAR-10 Batch 1:  cost is: 0.0756666\n",
      "accuracy is: 0.6574\n",
      "Epoch 54, CIFAR-10 Batch 2:  cost is: 0.100283\n",
      "accuracy is: 0.6602\n",
      "Epoch 54, CIFAR-10 Batch 3:  cost is: 0.0666948\n",
      "accuracy is: 0.6362\n",
      "Epoch 54, CIFAR-10 Batch 4:  cost is: 0.0863907\n",
      "accuracy is: 0.632\n",
      "Epoch 54, CIFAR-10 Batch 5:  cost is: 0.046989\n",
      "accuracy is: 0.651\n",
      "Epoch 55, CIFAR-10 Batch 1:  cost is: 0.0933639\n",
      "accuracy is: 0.6664\n",
      "Epoch 55, CIFAR-10 Batch 2:  cost is: 0.07548\n",
      "accuracy is: 0.6506\n",
      "Epoch 55, CIFAR-10 Batch 3:  cost is: 0.0526956\n",
      "accuracy is: 0.6496\n",
      "Epoch 55, CIFAR-10 Batch 4:  cost is: 0.100887\n",
      "accuracy is: 0.6296\n",
      "Epoch 55, CIFAR-10 Batch 5:  cost is: 0.0388481\n",
      "accuracy is: 0.6488\n",
      "Epoch 56, CIFAR-10 Batch 1:  cost is: 0.0749381\n",
      "accuracy is: 0.6522\n",
      "Epoch 56, CIFAR-10 Batch 2:  cost is: 0.0731881\n",
      "accuracy is: 0.647\n",
      "Epoch 56, CIFAR-10 Batch 3:  cost is: 0.044672\n",
      "accuracy is: 0.6454\n",
      "Epoch 56, CIFAR-10 Batch 4:  cost is: 0.0595188\n",
      "accuracy is: 0.6444\n",
      "Epoch 56, CIFAR-10 Batch 5:  cost is: 0.0466343\n",
      "accuracy is: 0.6462\n",
      "Epoch 57, CIFAR-10 Batch 1:  cost is: 0.0824436\n",
      "accuracy is: 0.6506\n",
      "Epoch 57, CIFAR-10 Batch 2:  cost is: 0.071253\n",
      "accuracy is: 0.6514\n",
      "Epoch 57, CIFAR-10 Batch 3:  cost is: 0.0452975\n",
      "accuracy is: 0.6454\n",
      "Epoch 57, CIFAR-10 Batch 4:  cost is: 0.0973248\n",
      "accuracy is: 0.6284\n",
      "Epoch 57, CIFAR-10 Batch 5:  cost is: 0.0580511\n",
      "accuracy is: 0.6358\n",
      "Epoch 58, CIFAR-10 Batch 1:  cost is: 0.0795185\n",
      "accuracy is: 0.6462\n",
      "Epoch 58, CIFAR-10 Batch 2:  cost is: 0.0544786\n",
      "accuracy is: 0.65\n",
      "Epoch 58, CIFAR-10 Batch 3:  cost is: 0.0404654\n",
      "accuracy is: 0.6406\n",
      "Epoch 58, CIFAR-10 Batch 4:  cost is: 0.0664261\n",
      "accuracy is: 0.649\n",
      "Epoch 58, CIFAR-10 Batch 5:  cost is: 0.0387033\n",
      "accuracy is: 0.6348\n",
      "Epoch 59, CIFAR-10 Batch 1:  cost is: 0.0597162\n",
      "accuracy is: 0.6534\n",
      "Epoch 59, CIFAR-10 Batch 2:  cost is: 0.0645959\n",
      "accuracy is: 0.6516\n",
      "Epoch 59, CIFAR-10 Batch 3:  cost is: 0.0313773\n",
      "accuracy is: 0.6416\n",
      "Epoch 59, CIFAR-10 Batch 4:  cost is: 0.0614809\n",
      "accuracy is: 0.6458\n",
      "Epoch 59, CIFAR-10 Batch 5:  cost is: 0.0470272\n",
      "accuracy is: 0.6458\n",
      "Epoch 60, CIFAR-10 Batch 1:  cost is: 0.0519616\n",
      "accuracy is: 0.6434\n",
      "Epoch 60, CIFAR-10 Batch 2:  cost is: 0.0549754\n",
      "accuracy is: 0.6412\n",
      "Epoch 60, CIFAR-10 Batch 3:  cost is: 0.0331792\n",
      "accuracy is: 0.6302\n",
      "Epoch 60, CIFAR-10 Batch 4:  cost is: 0.0584614\n",
      "accuracy is: 0.6424\n",
      "Epoch 60, CIFAR-10 Batch 5:  cost is: 0.0415539\n",
      "accuracy is: 0.6466\n",
      "Epoch 61, CIFAR-10 Batch 1:  cost is: 0.0503332\n",
      "accuracy is: 0.645\n",
      "Epoch 61, CIFAR-10 Batch 2:  cost is: 0.061987\n",
      "accuracy is: 0.649\n",
      "Epoch 61, CIFAR-10 Batch 3:  cost is: 0.0479681\n",
      "accuracy is: 0.6248\n",
      "Epoch 61, CIFAR-10 Batch 4:  cost is: 0.0674341\n",
      "accuracy is: 0.6446\n",
      "Epoch 61, CIFAR-10 Batch 5:  cost is: 0.0360394\n",
      "accuracy is: 0.6472\n",
      "Epoch 62, CIFAR-10 Batch 1:  cost is: 0.0653926\n",
      "accuracy is: 0.6472\n",
      "Epoch 62, CIFAR-10 Batch 2:  cost is: 0.0526179\n",
      "accuracy is: 0.6362\n",
      "Epoch 62, CIFAR-10 Batch 3:  cost is: 0.0306078\n",
      "accuracy is: 0.6352\n",
      "Epoch 62, CIFAR-10 Batch 4:  cost is: 0.0548479\n",
      "accuracy is: 0.6498\n",
      "Epoch 62, CIFAR-10 Batch 5:  cost is: 0.053903\n",
      "accuracy is: 0.648\n",
      "Epoch 63, CIFAR-10 Batch 1:  cost is: 0.0479638\n",
      "accuracy is: 0.6472\n",
      "Epoch 63, CIFAR-10 Batch 2:  cost is: 0.0574816\n",
      "accuracy is: 0.6528\n",
      "Epoch 63, CIFAR-10 Batch 3:  cost is: 0.0259332\n",
      "accuracy is: 0.6356\n",
      "Epoch 63, CIFAR-10 Batch 4:  cost is: 0.0788947\n",
      "accuracy is: 0.6376\n",
      "Epoch 63, CIFAR-10 Batch 5:  cost is: 0.024528\n",
      "accuracy is: 0.6562\n",
      "Epoch 64, CIFAR-10 Batch 1:  cost is: 0.070884\n",
      "accuracy is: 0.6416\n",
      "Epoch 64, CIFAR-10 Batch 2:  cost is: 0.0387601\n",
      "accuracy is: 0.633\n",
      "Epoch 64, CIFAR-10 Batch 3:  cost is: 0.029372\n",
      "accuracy is: 0.6386\n",
      "Epoch 64, CIFAR-10 Batch 4:  cost is: 0.0502684\n",
      "accuracy is: 0.6462\n",
      "Epoch 64, CIFAR-10 Batch 5:  cost is: 0.0220376\n",
      "accuracy is: 0.6494\n",
      "Epoch 65, CIFAR-10 Batch 1:  cost is: 0.0565771\n",
      "accuracy is: 0.6474\n",
      "Epoch 65, CIFAR-10 Batch 2:  cost is: 0.0327043\n",
      "accuracy is: 0.6524\n",
      "Epoch 65, CIFAR-10 Batch 3:  cost is: 0.0242245\n",
      "accuracy is: 0.6546\n",
      "Epoch 65, CIFAR-10 Batch 4:  cost is: 0.0468422\n",
      "accuracy is: 0.6594\n",
      "Epoch 65, CIFAR-10 Batch 5:  cost is: 0.0264334\n",
      "accuracy is: 0.645\n",
      "Epoch 66, CIFAR-10 Batch 1:  cost is: 0.0463895\n",
      "accuracy is: 0.6302\n",
      "Epoch 66, CIFAR-10 Batch 2:  cost is: 0.041349\n",
      "accuracy is: 0.6458\n",
      "Epoch 66, CIFAR-10 Batch 3:  cost is: 0.0204465\n",
      "accuracy is: 0.6452\n",
      "Epoch 66, CIFAR-10 Batch 4:  cost is: 0.0629947\n",
      "accuracy is: 0.6464\n",
      "Epoch 66, CIFAR-10 Batch 5:  cost is: 0.0513734\n",
      "accuracy is: 0.6366\n",
      "Epoch 67, CIFAR-10 Batch 1:  cost is: 0.0497773\n",
      "accuracy is: 0.6332\n",
      "Epoch 67, CIFAR-10 Batch 2:  cost is: 0.0380348\n",
      "accuracy is: 0.6454\n",
      "Epoch 67, CIFAR-10 Batch 3:  cost is: 0.0281152\n",
      "accuracy is: 0.646\n",
      "Epoch 67, CIFAR-10 Batch 4:  cost is: 0.0595509\n",
      "accuracy is: 0.6428\n",
      "Epoch 67, CIFAR-10 Batch 5:  cost is: 0.0307151\n",
      "accuracy is: 0.6488\n",
      "Epoch 68, CIFAR-10 Batch 1:  cost is: 0.0413004\n",
      "accuracy is: 0.6446\n",
      "Epoch 68, CIFAR-10 Batch 2:  cost is: 0.0396998\n",
      "accuracy is: 0.654\n",
      "Epoch 68, CIFAR-10 Batch 3:  cost is: 0.0267332\n",
      "accuracy is: 0.634\n",
      "Epoch 68, CIFAR-10 Batch 4:  cost is: 0.0402215\n",
      "accuracy is: 0.6438\n",
      "Epoch 68, CIFAR-10 Batch 5:  cost is: 0.0212457\n",
      "accuracy is: 0.6576\n",
      "Epoch 69, CIFAR-10 Batch 1:  cost is: 0.0400734\n",
      "accuracy is: 0.6354\n",
      "Epoch 69, CIFAR-10 Batch 2:  cost is: 0.0358041\n",
      "accuracy is: 0.6384\n",
      "Epoch 69, CIFAR-10 Batch 3:  cost is: 0.0157787\n",
      "accuracy is: 0.6446\n",
      "Epoch 69, CIFAR-10 Batch 4:  cost is: 0.0448505\n",
      "accuracy is: 0.6508\n",
      "Epoch 69, CIFAR-10 Batch 5:  cost is: 0.0261761\n",
      "accuracy is: 0.6562\n",
      "Epoch 70, CIFAR-10 Batch 1:  cost is: 0.0436198\n",
      "accuracy is: 0.6394\n",
      "Epoch 70, CIFAR-10 Batch 2:  cost is: 0.040335\n",
      "accuracy is: 0.6408\n",
      "Epoch 70, CIFAR-10 Batch 3:  cost is: 0.0192765\n",
      "accuracy is: 0.6378\n",
      "Epoch 70, CIFAR-10 Batch 4:  cost is: 0.0269887\n",
      "accuracy is: 0.6482\n",
      "Epoch 70, CIFAR-10 Batch 5:  cost is: 0.032101\n",
      "accuracy is: 0.6432\n",
      "Epoch 71, CIFAR-10 Batch 1:  cost is: 0.0339531\n",
      "accuracy is: 0.642\n",
      "Epoch 71, CIFAR-10 Batch 2:  cost is: 0.033481\n",
      "accuracy is: 0.64\n",
      "Epoch 71, CIFAR-10 Batch 3:  cost is: 0.0151729\n",
      "accuracy is: 0.653\n",
      "Epoch 71, CIFAR-10 Batch 4:  cost is: 0.0292848\n",
      "accuracy is: 0.6362\n",
      "Epoch 71, CIFAR-10 Batch 5:  cost is: 0.0192025\n",
      "accuracy is: 0.6538\n",
      "Epoch 72, CIFAR-10 Batch 1:  cost is: 0.0372803\n",
      "accuracy is: 0.6404\n",
      "Epoch 72, CIFAR-10 Batch 2:  cost is: 0.0305376\n",
      "accuracy is: 0.637\n",
      "Epoch 72, CIFAR-10 Batch 3:  cost is: 0.0254555\n",
      "accuracy is: 0.635\n",
      "Epoch 72, CIFAR-10 Batch 4:  cost is: 0.033822\n",
      "accuracy is: 0.6318\n",
      "Epoch 72, CIFAR-10 Batch 5:  cost is: 0.0295265\n",
      "accuracy is: 0.649\n",
      "Epoch 73, CIFAR-10 Batch 1:  cost is: 0.0306347\n",
      "accuracy is: 0.644\n",
      "Epoch 73, CIFAR-10 Batch 2:  cost is: 0.0251675\n",
      "accuracy is: 0.6416\n",
      "Epoch 73, CIFAR-10 Batch 3:  cost is: 0.0179854\n",
      "accuracy is: 0.6478\n",
      "Epoch 73, CIFAR-10 Batch 4:  cost is: 0.0474795\n",
      "accuracy is: 0.6294\n",
      "Epoch 73, CIFAR-10 Batch 5:  cost is: 0.0223804\n",
      "accuracy is: 0.6366\n",
      "Epoch 74, CIFAR-10 Batch 1:  cost is: 0.0399839\n",
      "accuracy is: 0.642\n",
      "Epoch 74, CIFAR-10 Batch 2:  cost is: 0.0318762\n",
      "accuracy is: 0.6524\n",
      "Epoch 74, CIFAR-10 Batch 3:  cost is: 0.0157505\n",
      "accuracy is: 0.6324\n",
      "Epoch 74, CIFAR-10 Batch 4:  cost is: 0.0429662\n",
      "accuracy is: 0.6222\n",
      "Epoch 74, CIFAR-10 Batch 5:  cost is: 0.020082\n",
      "accuracy is: 0.6424\n",
      "Epoch 75, CIFAR-10 Batch 1:  cost is: 0.0261554\n",
      "accuracy is: 0.649\n",
      "Epoch 75, CIFAR-10 Batch 2:  cost is: 0.0262008\n",
      "accuracy is: 0.6506\n",
      "Epoch 75, CIFAR-10 Batch 3:  cost is: 0.0149603\n",
      "accuracy is: 0.6518\n",
      "Epoch 75, CIFAR-10 Batch 4:  cost is: 0.0289169\n",
      "accuracy is: 0.645\n",
      "Epoch 75, CIFAR-10 Batch 5:  cost is: 0.0141111\n",
      "accuracy is: 0.6436\n",
      "Epoch 76, CIFAR-10 Batch 1:  cost is: 0.028754\n",
      "accuracy is: 0.654\n",
      "Epoch 76, CIFAR-10 Batch 2:  cost is: 0.0317258\n",
      "accuracy is: 0.6394\n",
      "Epoch 76, CIFAR-10 Batch 3:  cost is: 0.0125936\n",
      "accuracy is: 0.6356\n",
      "Epoch 76, CIFAR-10 Batch 4:  cost is: 0.0270463\n",
      "accuracy is: 0.6402\n",
      "Epoch 76, CIFAR-10 Batch 5:  cost is: 0.0193909\n",
      "accuracy is: 0.6482\n",
      "Epoch 77, CIFAR-10 Batch 1:  cost is: 0.0304984\n",
      "accuracy is: 0.6466\n",
      "Epoch 77, CIFAR-10 Batch 2:  cost is: 0.022903\n",
      "accuracy is: 0.6478\n",
      "Epoch 77, CIFAR-10 Batch 3:  cost is: 0.0145331\n",
      "accuracy is: 0.6292\n",
      "Epoch 77, CIFAR-10 Batch 4:  cost is: 0.024696\n",
      "accuracy is: 0.639\n",
      "Epoch 77, CIFAR-10 Batch 5:  cost is: 0.0203662\n",
      "accuracy is: 0.6432\n",
      "Epoch 78, CIFAR-10 Batch 1:  cost is: 0.0334503\n",
      "accuracy is: 0.6472\n",
      "Epoch 78, CIFAR-10 Batch 2:  cost is: 0.0230093\n",
      "accuracy is: 0.6588\n",
      "Epoch 78, CIFAR-10 Batch 3:  cost is: 0.0152752\n",
      "accuracy is: 0.6562\n",
      "Epoch 78, CIFAR-10 Batch 4:  cost is: 0.015302\n",
      "accuracy is: 0.649\n",
      "Epoch 78, CIFAR-10 Batch 5:  cost is: 0.0184164\n",
      "accuracy is: 0.6452\n",
      "Epoch 79, CIFAR-10 Batch 1:  cost is: 0.0218981\n",
      "accuracy is: 0.649\n",
      "Epoch 79, CIFAR-10 Batch 2:  cost is: 0.017508\n",
      "accuracy is: 0.6512\n",
      "Epoch 79, CIFAR-10 Batch 3:  cost is: 0.0122434\n",
      "accuracy is: 0.6384\n",
      "Epoch 79, CIFAR-10 Batch 4:  cost is: 0.0239416\n",
      "accuracy is: 0.6376\n",
      "Epoch 79, CIFAR-10 Batch 5:  cost is: 0.0256885\n",
      "accuracy is: 0.6494\n",
      "Epoch 80, CIFAR-10 Batch 1:  cost is: 0.0199868\n",
      "accuracy is: 0.6422\n",
      "Epoch 80, CIFAR-10 Batch 2:  cost is: 0.0104822\n",
      "accuracy is: 0.6498\n",
      "Epoch 80, CIFAR-10 Batch 3:  cost is: 0.0112864\n",
      "accuracy is: 0.651\n",
      "Epoch 80, CIFAR-10 Batch 4:  cost is: 0.0270612\n",
      "accuracy is: 0.6356\n",
      "Epoch 80, CIFAR-10 Batch 5:  cost is: 0.0217615\n",
      "accuracy is: 0.642\n",
      "Epoch 81, CIFAR-10 Batch 1:  cost is: 0.0150574\n",
      "accuracy is: 0.6482\n",
      "Epoch 81, CIFAR-10 Batch 2:  cost is: 0.0144324\n",
      "accuracy is: 0.6626\n",
      "Epoch 81, CIFAR-10 Batch 3:  cost is: 0.0149396\n",
      "accuracy is: 0.6442\n",
      "Epoch 81, CIFAR-10 Batch 4:  cost is: 0.0213412\n",
      "accuracy is: 0.656\n",
      "Epoch 81, CIFAR-10 Batch 5:  cost is: 0.0157074\n",
      "accuracy is: 0.6298\n",
      "Epoch 82, CIFAR-10 Batch 1:  cost is: 0.0226222\n",
      "accuracy is: 0.656\n",
      "Epoch 82, CIFAR-10 Batch 2:  cost is: 0.0222815\n",
      "accuracy is: 0.6364\n",
      "Epoch 82, CIFAR-10 Batch 3:  cost is: 0.0289943\n",
      "accuracy is: 0.641\n",
      "Epoch 82, CIFAR-10 Batch 4:  cost is: 0.0223025\n",
      "accuracy is: 0.6442\n",
      "Epoch 82, CIFAR-10 Batch 5:  cost is: 0.0273988\n",
      "accuracy is: 0.6426\n",
      "Epoch 83, CIFAR-10 Batch 1:  cost is: 0.0257501\n",
      "accuracy is: 0.6428\n",
      "Epoch 83, CIFAR-10 Batch 2:  cost is: 0.0182273\n",
      "accuracy is: 0.6502\n",
      "Epoch 83, CIFAR-10 Batch 3:  cost is: 0.0184244\n",
      "accuracy is: 0.6416\n",
      "Epoch 83, CIFAR-10 Batch 4:  cost is: 0.0283415\n",
      "accuracy is: 0.6478\n",
      "Epoch 83, CIFAR-10 Batch 5:  cost is: 0.0256566\n",
      "accuracy is: 0.6376\n",
      "Epoch 84, CIFAR-10 Batch 1:  cost is: 0.0228408\n",
      "accuracy is: 0.643\n",
      "Epoch 84, CIFAR-10 Batch 2:  cost is: 0.0304994\n",
      "accuracy is: 0.628\n",
      "Epoch 84, CIFAR-10 Batch 3:  cost is: 0.0238602\n",
      "accuracy is: 0.6448\n",
      "Epoch 84, CIFAR-10 Batch 4:  cost is: 0.0364732\n",
      "accuracy is: 0.6368\n",
      "Epoch 84, CIFAR-10 Batch 5:  cost is: 0.0229581\n",
      "accuracy is: 0.6478\n",
      "Epoch 85, CIFAR-10 Batch 1:  cost is: 0.0166243\n",
      "accuracy is: 0.6518\n",
      "Epoch 85, CIFAR-10 Batch 2:  cost is: 0.0225714\n",
      "accuracy is: 0.6432\n",
      "Epoch 85, CIFAR-10 Batch 3:  cost is: 0.0233655\n",
      "accuracy is: 0.639\n",
      "Epoch 85, CIFAR-10 Batch 4:  cost is: 0.0313438\n",
      "accuracy is: 0.6592\n",
      "Epoch 85, CIFAR-10 Batch 5:  cost is: 0.0272653\n",
      "accuracy is: 0.6604\n",
      "Epoch 86, CIFAR-10 Batch 1:  cost is: 0.0274737\n",
      "accuracy is: 0.6558\n",
      "Epoch 86, CIFAR-10 Batch 2:  cost is: 0.0347555\n",
      "accuracy is: 0.6356\n",
      "Epoch 86, CIFAR-10 Batch 3:  cost is: 0.0123148\n",
      "accuracy is: 0.644\n",
      "Epoch 86, CIFAR-10 Batch 4:  cost is: 0.0199896\n",
      "accuracy is: 0.653\n",
      "Epoch 86, CIFAR-10 Batch 5:  cost is: 0.0257322\n",
      "accuracy is: 0.65\n",
      "Epoch 87, CIFAR-10 Batch 1:  cost is: 0.0273452\n",
      "accuracy is: 0.641\n",
      "Epoch 87, CIFAR-10 Batch 2:  cost is: 0.0235511\n",
      "accuracy is: 0.643\n",
      "Epoch 87, CIFAR-10 Batch 3:  cost is: 0.0186474\n",
      "accuracy is: 0.6474\n",
      "Epoch 87, CIFAR-10 Batch 4:  cost is: 0.0175845\n",
      "accuracy is: 0.6506\n",
      "Epoch 87, CIFAR-10 Batch 5:  cost is: 0.0203131\n",
      "accuracy is: 0.645\n",
      "Epoch 88, CIFAR-10 Batch 1:  cost is: 0.0256467\n",
      "accuracy is: 0.644\n",
      "Epoch 88, CIFAR-10 Batch 2:  cost is: 0.0177962\n",
      "accuracy is: 0.6378\n",
      "Epoch 88, CIFAR-10 Batch 3:  cost is: 0.00959316\n",
      "accuracy is: 0.6522\n",
      "Epoch 88, CIFAR-10 Batch 4:  cost is: 0.0124762\n",
      "accuracy is: 0.6478\n",
      "Epoch 88, CIFAR-10 Batch 5:  cost is: 0.0119275\n",
      "accuracy is: 0.6472\n",
      "Epoch 89, CIFAR-10 Batch 1:  cost is: 0.0255844\n",
      "accuracy is: 0.6464\n",
      "Epoch 89, CIFAR-10 Batch 2:  cost is: 0.0202244\n",
      "accuracy is: 0.648\n",
      "Epoch 89, CIFAR-10 Batch 3:  cost is: 0.0138984\n",
      "accuracy is: 0.6458\n",
      "Epoch 89, CIFAR-10 Batch 4:  cost is: 0.0183139\n",
      "accuracy is: 0.6572\n",
      "Epoch 89, CIFAR-10 Batch 5:  cost is: 0.011877\n",
      "accuracy is: 0.6414\n",
      "Epoch 90, CIFAR-10 Batch 1:  cost is: 0.0185905\n",
      "accuracy is: 0.6242\n",
      "Epoch 90, CIFAR-10 Batch 2:  cost is: 0.0212963\n",
      "accuracy is: 0.6446\n",
      "Epoch 90, CIFAR-10 Batch 3:  cost is: 0.0123183\n",
      "accuracy is: 0.6536\n",
      "Epoch 90, CIFAR-10 Batch 4:  cost is: 0.0176371\n",
      "accuracy is: 0.6394\n",
      "Epoch 90, CIFAR-10 Batch 5:  cost is: 0.0160692\n",
      "accuracy is: 0.6498\n",
      "Epoch 91, CIFAR-10 Batch 1:  cost is: 0.0138106\n",
      "accuracy is: 0.6536\n",
      "Epoch 91, CIFAR-10 Batch 2:  cost is: 0.0326715\n",
      "accuracy is: 0.6422\n",
      "Epoch 91, CIFAR-10 Batch 3:  cost is: 0.0119494\n",
      "accuracy is: 0.6386\n",
      "Epoch 91, CIFAR-10 Batch 4:  cost is: 0.0145028\n",
      "accuracy is: 0.6448\n",
      "Epoch 91, CIFAR-10 Batch 5:  cost is: 0.0187942\n",
      "accuracy is: 0.6494\n",
      "Epoch 92, CIFAR-10 Batch 1:  cost is: 0.0141233\n",
      "accuracy is: 0.6534\n",
      "Epoch 92, CIFAR-10 Batch 2:  cost is: 0.0129619\n",
      "accuracy is: 0.6368\n",
      "Epoch 92, CIFAR-10 Batch 3:  cost is: 0.00867002\n",
      "accuracy is: 0.657\n",
      "Epoch 92, CIFAR-10 Batch 4:  cost is: 0.022928\n",
      "accuracy is: 0.6422\n",
      "Epoch 92, CIFAR-10 Batch 5:  cost is: 0.014243\n",
      "accuracy is: 0.6458\n",
      "Epoch 93, CIFAR-10 Batch 1:  cost is: 0.0132764\n",
      "accuracy is: 0.6572\n",
      "Epoch 93, CIFAR-10 Batch 2:  cost is: 0.01157\n",
      "accuracy is: 0.6366\n",
      "Epoch 93, CIFAR-10 Batch 3:  cost is: 0.0103694\n",
      "accuracy is: 0.6548\n",
      "Epoch 93, CIFAR-10 Batch 4:  cost is: 0.0210182\n",
      "accuracy is: 0.6356\n",
      "Epoch 93, CIFAR-10 Batch 5:  cost is: 0.0097257\n",
      "accuracy is: 0.6502\n",
      "Epoch 94, CIFAR-10 Batch 1:  cost is: 0.0125961\n",
      "accuracy is: 0.6606\n",
      "Epoch 94, CIFAR-10 Batch 2:  cost is: 0.0169219\n",
      "accuracy is: 0.6334\n",
      "Epoch 94, CIFAR-10 Batch 3:  cost is: 0.00627015\n",
      "accuracy is: 0.649\n",
      "Epoch 94, CIFAR-10 Batch 4:  cost is: 0.0148446\n",
      "accuracy is: 0.6472\n",
      "Epoch 94, CIFAR-10 Batch 5:  cost is: 0.00941635\n",
      "accuracy is: 0.6548\n",
      "Epoch 95, CIFAR-10 Batch 1:  cost is: 0.0202758\n",
      "accuracy is: 0.6574\n",
      "Epoch 95, CIFAR-10 Batch 2:  cost is: 0.0315425\n",
      "accuracy is: 0.6312\n",
      "Epoch 95, CIFAR-10 Batch 3:  cost is: 0.012403\n",
      "accuracy is: 0.6488\n",
      "Epoch 95, CIFAR-10 Batch 4:  cost is: 0.0117807\n",
      "accuracy is: 0.6512\n",
      "Epoch 95, CIFAR-10 Batch 5:  cost is: 0.0123639\n",
      "accuracy is: 0.6598\n",
      "Epoch 96, CIFAR-10 Batch 1:  cost is: 0.0171643\n",
      "accuracy is: 0.6564\n",
      "Epoch 96, CIFAR-10 Batch 2:  cost is: 0.00972694\n",
      "accuracy is: 0.6536\n",
      "Epoch 96, CIFAR-10 Batch 3:  cost is: 0.00954378\n",
      "accuracy is: 0.6504\n",
      "Epoch 96, CIFAR-10 Batch 4:  cost is: 0.0213914\n",
      "accuracy is: 0.6396\n",
      "Epoch 96, CIFAR-10 Batch 5:  cost is: 0.00764408\n",
      "accuracy is: 0.6578\n",
      "Epoch 97, CIFAR-10 Batch 1:  cost is: 0.0125829\n",
      "accuracy is: 0.6628\n",
      "Epoch 97, CIFAR-10 Batch 2:  cost is: 0.0169667\n",
      "accuracy is: 0.639\n",
      "Epoch 97, CIFAR-10 Batch 3:  cost is: 0.0096555\n",
      "accuracy is: 0.6462\n",
      "Epoch 97, CIFAR-10 Batch 4:  cost is: 0.00880287\n",
      "accuracy is: 0.6538\n",
      "Epoch 97, CIFAR-10 Batch 5:  cost is: 0.00553141\n",
      "accuracy is: 0.6664\n",
      "Epoch 98, CIFAR-10 Batch 1:  cost is: 0.0174343\n",
      "accuracy is: 0.6518\n",
      "Epoch 98, CIFAR-10 Batch 2:  cost is: 0.0167557\n",
      "accuracy is: 0.6394\n",
      "Epoch 98, CIFAR-10 Batch 3:  cost is: 0.0116103\n",
      "accuracy is: 0.6532\n",
      "Epoch 98, CIFAR-10 Batch 4:  cost is: 0.0153767\n",
      "accuracy is: 0.654\n",
      "Epoch 98, CIFAR-10 Batch 5:  cost is: 0.0108731\n",
      "accuracy is: 0.6586\n",
      "Epoch 99, CIFAR-10 Batch 1:  cost is: 0.0231528\n",
      "accuracy is: 0.6438\n",
      "Epoch 99, CIFAR-10 Batch 2:  cost is: 0.0163903\n",
      "accuracy is: 0.6448\n",
      "Epoch 99, CIFAR-10 Batch 3:  cost is: 0.0126285\n",
      "accuracy is: 0.6424\n",
      "Epoch 99, CIFAR-10 Batch 4:  cost is: 0.0145828\n",
      "accuracy is: 0.6576\n",
      "Epoch 99, CIFAR-10 Batch 5:  cost is: 0.0143274\n",
      "accuracy is: 0.6514\n",
      "Epoch 100, CIFAR-10 Batch 1:  cost is: 0.00988194\n",
      "accuracy is: 0.6578\n",
      "Epoch 100, CIFAR-10 Batch 2:  cost is: 0.0204865\n",
      "accuracy is: 0.6498\n",
      "Epoch 100, CIFAR-10 Batch 3:  cost is: 0.011042\n",
      "accuracy is: 0.648\n",
      "Epoch 100, CIFAR-10 Batch 4:  cost is: 0.0284009\n",
      "accuracy is: 0.6414\n",
      "Epoch 100, CIFAR-10 Batch 5:  cost is: 0.0147568\n",
      "accuracy is: 0.6498\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.657421875\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWoMx5IkSVLzfwHTpOp/ex2CAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28b8773f518>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
